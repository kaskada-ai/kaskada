{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "html_theme.sidebar_secondary.remove: true\n",
        "sd_hide_title: true\n",
        "---"
      ],
      "id": "703a84c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Real-Time AI without the fuss.\n",
        "\n",
        "<div class=\"px-4 py-5 my-5 text-center\">\n",
        "    <img class=\"d-block mx-auto mb-4 only-light\" src=\"_static/kaskada-positive.svg\" alt=\"\" width=\"50%\">\n",
        "    <img class=\"d-block mx-auto mb-4 only-dark\" src=\"_static/kaskada-negative.svg\" alt=\"\" width=\"50%\">\n",
        "    <h1 class=\"display-5 fw-bold\">Real-Time AI without the fuss.</h1>\n",
        "    <div class=\"col-lg-7 mx-auto\">\n",
        "      <p class=\"lead mb-4\">Kaskada is a next-generation streaming engine that connects AI models to real-time & historical data.\n",
        "      </p>\n",
        "    </div>\n",
        "</div>\n",
        "\n",
        "## Kaskada completes the Real-Time AI stack, providing...\n",
        "\n",
        "```{gallery-grid}\n",
        ":grid-columns: 1 2 2 3\n",
        "\n",
        "- header: \"{fas}`timeline;pst-color-primary` Real-time Aggregation\"\n",
        "  content: \"Precompute model inputs from streaming data with robust data connectors, transformations & aggregations.\"\n",
        "- header: \"{fas}`binoculars;pst-color-primary` Event Detection\"\n",
        "  content: \"Trigger pro-active AI behaviors by identifying important activities, as they happen.\"\n",
        "- header: \"{fas}`backward;pst-color-primary` History Replay\"\n",
        "  content: \"Backtest and fine-tune from historical data using per-example time travel and point-in-time joins.\"\n",
        "```\n",
        "\n",
        "\n",
        "## Real-time AI in minutes\n",
        "\n",
        "Connect and compute over databases, streaming data, _and_ data loaded dynamically using Python..\n",
        "Kaskada is seamlessly integrated with Python's ecosystem of AI/ML tooling so you can load data, process it, train and serve models all in the same place.\n",
        "\n",
        "There's no infrastructure to provision (and no JVM hiding under the covers), so you can jump right in - check out the [Quick Start](./guide/quickstart.md).\n",
        "\n",
        "\n",
        "## Built for scale and reliability\n",
        "\n",
        "Implemented in [Rust](https://www.rust-lang.org/) using [Apache Arrow](https://arrow.apache.org/), Kaskada's compute engine uses columnar data to efficiently execute large historic and high-throughput streaming queries.\n",
        "Every operation in Kaskada is implemented incrementally, allowing automatic recovery if the process is terminated or killed.\n",
        "\n",
        "With Kaskada, most jobs are fast enough to run locally, so it's easy to build and test your real-time queries.\n",
        "As your needs grow, Kaskada's cloud-native design and support for partitioned execution gives you the volume and throughput you need to scale.\n",
        "Kaskada was built by core contributors to [Apache Beam](https://beam.apache.org/), [Google Cloud Dataflow](https://cloud.google.com/dataflow), and [Apache Cassandra](https://cassandra.apache.org/), and is under active development\n",
        "\n",
        "* * *\n",
        "\n",
        "## Example Real-Time App: BeepGPT\n",
        "\n",
        "[BeepGPT](https://github.com/kaskada-ai/beep-gpt/tree/main) keeps you in the loop without disturbing your focus. Its personalized, intelligent AI continuously monitors your Slack workspace, alerting you to important conversations and freeing you to concentrate on whatâ€™s most important.\n",
        "\n",
        "The core of BeepGPT's real-time processing requires only a few lines of code using Kaskada:\n",
        "\n",
        "```python\n",
        "import asyncio\n",
        "import kaskada as kd\n",
        "kd.init_session()\n",
        "\n",
        "# Bootstrap from historical data\n",
        "messages = await kd.sources.PyDict.create(\n",
        "    rows = pyarrow.parquet.read_table(\"./messages.parquet\")\n",
        "        .to_pylist(),\n",
        "    time_column = \"ts\",\n",
        "    key_column = \"channel\",\n",
        ")\n",
        "\n",
        "# Send each Slack message to Kaskada\n",
        "def handle_message(client, req):\n",
        "    messages.add_rows(req.payload[\"event\"])\n",
        "slack.socket_mode_request_listeners.append(handle_message)\n",
        "slack.connect()\n",
        "\n",
        "# Aggregate multiple messages into a \"conversation\"\n",
        "conversations = ( messages\n",
        "    .select(\"user\", \"text\")\n",
        "    .collect(max=20)\n",
        ")\n",
        "\n",
        "# Handle each conversation as it occurs\n",
        "async for row in conversations.run_iter(mode='live'):\n",
        "\n",
        "    # Use a pre-trained model to identify interested users\n",
        "    prompt = \"\\n\\n\".join([f' {msg[\"user\"]} --> {msg[\"text\"]} ' for msg in row[\"result\"]])\n",
        "    res = openai.Completion.create(\n",
        "        model=\"davinci:ft-personal:coversation-users-full-kaskada-2023-08-05-14-25-30\",\n",
        "        prompt=prompt + \"\\n\\n###\\n\\n\",\n",
        "        logprobs=5,\n",
        "        max_tokens=1,\n",
        "        stop=\" end\",\n",
        "        temperature=0.25,\n",
        "    )\n",
        "\n",
        "    # Notify interested users using the Slack API\n",
        "    for user_id in interested_users(res):\n",
        "        notify_user(row, user_id)\n",
        "```\n",
        "\n",
        "For more details, check out the [BeepGPT Github project](https://github.com/kaskada-ai/beep-gpt).\n",
        "\n",
        "* * *\n",
        "\n",
        "## Get Started\n",
        "\n",
        "Getting started with Kaskda is a `pip install kaskada` away.\n",
        "Check out the [Quick Start](./guide/quickstart.md) now!\n",
        "\n",
        "\n",
        "```{toctree}\n",
        ":hidden:\n",
        ":maxdepth: 3\n",
        "\n",
        "guide/index\n",
        "examples/index\n",
        "reference/index\n",
        "blog/index\n",
        "```"
      ],
      "id": "1c0e65d2"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}