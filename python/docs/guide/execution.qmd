---
title: Execution
---

A [Timestream](./timestreams.qmd) may be executed and written to a [destination](#destinations) in a variety of ways.
The things to consider when deciding how to execute the Timestream are:

1. Whether you want the _history_ of points or the _snapshot_ of values for each entity at a given time.
2. Whether you want to run a query _once_ or start a _live_ process continually materializing.
3. Whether you want to limit the output to points in a specific time range (for history) or entities that have changed since a specific time (for snapshots).
4. Whether you want to stop at a given point in time.

[State](#state) can be used to provide fault-tolerance and allow incremental processing of only new events.

::: {.callout-tip title="Preview during development"}
While developing queries, it is often useful to view a few rows from the result.
Using [](`kaskada.Timestream.preview`) you can retrieve a small set of rows from the result set as a Pandas DataFrame.
:::

## History vs. Snapshot

Executing a Timestream for the history outputs every point in the Timestream.
This means that each entity likely appears in the output multiple times.
This is particularly useful for creating training examples from past data points, or visualizing how the Timestream has changed over time.

```{code-cell} python
import asyncio
import kaskada as kd
kd.init_session()
data = "\n".join(
    [
        "time,key,m",
        "1996-12-19T16:39:57,A,5",
        "1996-12-19T17:42:57,B,8",
        "1996-12-19T18:13:43,C,1",
        "1996-12-20T16:39:59,A,17",
        "1996-12-23T12:18:57,B,6",
        "1996-12-23T16:40:01,A,12",
    ]
)
ts = await kd.sources.CsvString.create(data, time_column="time", key_column="key")

# Execute the expression as a history
ts.to_pandas(results=kd.results.History())
```

Executing a Timestream for a snapshot produces a value for each entity at a specific point in time.
This means that each entity appears at-most once in the results.
This is useful for maintaining a feature store based on the latest values.

```{code-cell} python
# Execute the expression as a snapshot
ts.to_pandas(results=kd.results.Snapshot())
```

## Once vs. Live

Every Timestream may be executed "once" using the data currently present in the sources you've defined or executed "live", producuing new results as data is added to those sources.
"Once" execution suseful when you want the results for a batch process, such as fine-tuning a model or populating an in-memory feature store.

```{code-cell} python
for res in ts.run_iter(mode="once"):
    print(res)
```

"Live" execution is useful when you want to stream new results out as quickly as possible, such as maintaining an in-memory feature store or reacting to specific conditions.

```{code-block} python
async def run_background():
    async for res in ts.run_iter(mode="live"):
        print(res)

asyncio.create_task(run_background())
await ts.add_string("time,key,m\n1996-12-24T16:40:01,D,12")
```

## Changed Since

Configuring the _changed since time_ lets you control the points or entities included in the output.

For a historic query, only points occurring after the changed since time are included in the output.
This allows incrementally outputting the entire history to some external store, by repeatedly performing a "changed since" query.

```{code-cell} python
import datetime as dt

ts.to_pandas(
    results=kd.results.History(since=dt.datetime(1996, 12, 20, 0, 0, 0)),
)
```

For a snapshot query, only entities that have changed after this time are included in the output.
This reduces the amount of data written when the past snapshot is already present in the destination

```{code-cell} python
ts.to_pandas(
    results=kd.results.Snapshot(changed_since=dt.datetime(1996, 12, 20, 0, 0, 0)),
)
```

## Up To

Configuring the _up to time_ lets you control the maximum points output (and in the case of snapshots, the time represented in the snapshot).

For a historic query, only points occurring before or at the up to time are included in the output.

```{code-cell} python
import datetime as dt

ts.to_pandas(
    results=kd.results.History(until=dt.datetime(1996, 12, 20, 0, 0, 0)),
)
```

For a snapshot query, this corresponds to the time at which the snapshot will be taken.

```{code-cell} python
ts.to_pandas(
    results=kd.results.Snapshot(at=dt.datetime(1996, 12, 20, 0, 0, 0)),
)
```

```{note}
Currently when not specified, the up to time is determined from the maximum event present in the data.
```

## Destinations

The methods [](`kaskada.Timestream.preview`) and [](`kaskada.Timestream.to_pandas`) provide the results of a query in a Pandas DataFrame for easy visualization and consumption within the Python process.

The [](`kaskada.Timestream.run_iter`) methods provides synchronous and asynchronous iterators over the results in a variety of formats including Pandas DataFrames, PyArrow RecordBatches, and rows as Python dictionaries.
This allows you to run the entire retrieve-evaluate-respond loop within a single Python process.

The [](`kaskada.Timestream.write`) function allows you to specify a destination from [`kaskada.destinations`](../reference/Destinations/index.qmd) for results.
This supports both `once` and `live` queries
See the reference on [destinations](../reference/Destinations/index.qmd) for more on the supported destinations.

## Durability

At the moment, "live" Kaskada queries do not durably persist their progress - results are returned for the full data set each time {py:func}`Timestream.run_iter<kaskada.Timestream.run_iter>` is called. 
The ability to automatically persists progress is under active development.

Similarly, values added to dynamic data sources (for example [](`kaskada.sources.PyDict`) are not currently persisted durably. 
By default, such values are retained in memory - to discard values after they're processed specify `queryable=False` when creating the data source. 
