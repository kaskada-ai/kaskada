{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81791ea0",
   "metadata": {},
   "source": [
    "# Kaskada with CSV\n",
    "\n",
    "**Goal:** Demonstrate the new feature work for Kaskada to operate on CSV data. This work is scheduled for demo on 2/28/2023."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7fe26d",
   "metadata": {},
   "source": [
    "## Generating CSV Data\n",
    "\n",
    "The section below generates a basic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8932954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import names\n",
    "import pandas\n",
    "\n",
    "def generate_dataset(num_members, num_records_per_member):\n",
    "    member_ids = list(range(0, num_members))\n",
    "    column_1_name = 'amount'\n",
    "    column_2_name = 'random_col'\n",
    "    records = []\n",
    "    for member_id in member_ids:\n",
    "        for i in range(0, num_records_per_member):\n",
    "            records.append({\n",
    "                'id': member_id,\n",
    "                'time': random.randint(1000000000000000, 9000000000000000), # number of seconds from epoch\n",
    "                'name': f\"my-cool-name-{random.randint(-100, 100)}\",\n",
    "                column_1_name : random.randint(-100, 100),\n",
    "                column_2_name : f\"some-value-{random.randint(0, 100)}\"\n",
    "            })\n",
    "\n",
    "    df = pandas.DataFrame(records)\n",
    "    df['time']= pandas.to_datetime(df['time'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de4153",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = generate_dataset(100, 5)\n",
    "dataset1.to_csv('dataset1.csv')\n",
    "dataset1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66bbfa",
   "metadata": {},
   "source": [
    "## Launch Kaskada\n",
    "\n",
    "There is no additional configuration Kaskada needs to utilize CSV. Simply create a table or use an existing table, and load the CSV data to the table. Previously, the python client library used PyArrow to convert CSV to Parquet prior to ingestion but now this constraint is removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f121f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaskada.api.session import LocalBuilder\n",
    "session = LocalBuilder().download(False).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dace5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaskada.table\n",
    "# Create the table named transactions with the time and name column\n",
    "kaskada.table.create_table('transactions', 'time', 'name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40008105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data to the table\n",
    "kaskada.table.load('transactions', 'dataset1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0752147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the table and see the version is incremented and the schema is available.\n",
    "kaskada.table.get_table('transactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852448de",
   "metadata": {},
   "source": [
    "## Run a query with Fenlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c2f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext fenlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ae92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fenl\n",
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c95917",
   "metadata": {},
   "source": [
    "## More Data\n",
    "\n",
    "Add more data with additional CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d2d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = generate_dataset(100, 50) #5000\n",
    "dataset2.to_csv('dataset2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22a72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaskada.table.load('transactions', 'dataset2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba89181",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fenl\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c3955",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fenl --output=csv\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1caaf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a73044caba96c9b65200f613888b01ede560b58bfea27aeaeca02e7a5f7b80b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
