{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235d821b-1ff8-4ef6-8f0b-559c95254479",
   "metadata": {},
   "source": [
    "# Slackbot Example\n",
    "\n",
    "SlackBot keeps you in the loop without disturbing your focus. Its personalized, intelligent AI continuously monitors your Slack workspace, alerting you to important conversations and freeing you to concentrate on what’s most important.\n",
    "\n",
    "SlackBot reads the full history of your (public) Slack workspace and trains a Generative AI model to predict when you need to engage with a conversation. This training process gives the AI a deep understanding of your interests, expertise, and relationships. Using this understanding, SlackBot watches conversations in real-time and notifies you when an important conversation is happening without you. With SlackBot200 you can focus on getting things done without worrying about missing out.\n",
    "\n",
    "In this notebook, you’ll see you how to build and deploy SlackBot in 15 minutes using only OpenAI’s API’s and open-source Python libraries - Data Science PhD not required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70440303",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai kaskada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95d4d50",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_546/897995286.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkaskada\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "import openai\n",
    "import kaskada as k\n",
    "\n",
    "def prompt(messages):\n",
    "    last_message = messages.lag(1)\n",
    "    since_last_message = messages.time_of().seconds_between(last_message.time_of())\n",
    "    conversation_start = since_last_message > k.minutes(5)\n",
    "\n",
    "    k.make_record( \n",
    "        # A list of all messages over the past 10 minutes (up to 100)\n",
    "        recent_messages=messages\n",
    "            .select(\"user\", \"type\", \"text\")\n",
    "            .collect(window=since(conversation_start), max=100),\n",
    "\n",
    "        # How many messages have been reacted to in the conversation\n",
    "        reaction_count=messages\n",
    "            .when(messages.col(\"reactions\").is_not_null())\n",
    "            .count(window=since(conversation_start)),\n",
    "    )\n",
    "\n",
    "def examples(messages):\n",
    "    k.make_record(\n",
    "        prompt=prompt(messages).lag(1).lookup(messages.get(\"channel\")),\n",
    "\n",
    "        # We'll train ChatGPT to generate the user ID who will engage next\n",
    "        completion=completion.col(\"user_id\"),\n",
    "    )\n",
    "\n",
    "def main():\n",
    "    # Initialize Kaskada with a local execution context.\n",
    "    k.init_session()\n",
    "\n",
    "    tl = examples(messages = k.ParquetSource(files=[\"./messages.parquet\"]))\n",
    "    tl = tl.when(tl.col(\"prompt\").is_valid())\n",
    "    examples_df = tl.run().to_pandas()\n",
    "\n",
    "    # Split training & validation\n",
    "\n",
    "    train, valid = train_test_split(examples_df, test_size=0.2, random_state=42)\n",
    "    train.to_json(\"train.jsonl\", orient='records', lines=True)\n",
    "    valid.to_json(\"valid.jsonl\", orient='records', lines=True)\n",
    "\n",
    "    # Fine tune a model\n",
    "    !openai api fine_tunes.create -t \"train.jsonl\" -v \"valid.jsonl\"\n",
    "\n",
    "    # Apply in real-time\n",
    "    live_messages = k.StreamSource()\n",
    "\n",
    "    # TODO: Spawn a Slack listener\n",
    "\n",
    "    # Handle messages in realtime\n",
    "    for p in prompt(live_messages).run(starting=datetime.now()).to_generator():\n",
    "        completions = openai.ChatCompletion.create(\n",
    "            model=\"ft-2zaA7qi0rxJduWQpdvOvmGn3\", \n",
    "            messages=[{\"role\": \"user\", \"content\": p}],\n",
    "            n=5, logprobs=5,\n",
    "        )\n",
    "        for completion in completions:\n",
    "            if sum(completion.logprobs) > 0.05:\n",
    "                user = completion.completion\n",
    "                # Use the Slack API to PM the user?\n",
    "                print(f\"Notify {user} of conversation: \\n{p}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd2b13",
   "metadata": {},
   "source": [
    "## Legacy Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d9d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext fenlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac261293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaskada.api.session import LocalBuilder\n",
    "from kaskada import table\n",
    "\n",
    "session = LocalBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7c0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table.delete_table(\"Message\")\n",
    "\n",
    "table.create_table(\n",
    "  # The table's name\n",
    "  table_name = \"Message\",\n",
    "  # The name of the column in the data that contains the time associated with each row\n",
    "  time_column_name = \"ts\",\n",
    "  # The name of the column in the data that contains the entity key associated with each row\n",
    "  entity_key_column_name = \"channel\",\n",
    "  grouping_id = \"Channel\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8df2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table.load(table_name = \"Message\", file = \"messages.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2b745",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fenl\n",
    "Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fenl\n",
    "let message = Message | when(Message.subtype == \"message\")\n",
    "\n",
    "let prompt = {\n",
    "    # TODO: List rather than last\n",
    "    recent_messages: message | select_fields($input, \"user\", \"text\") | last(),\n",
    "\n",
    "    # # TODO: List support (for reactions field)\n",
    "    # engage_count: message\n",
    "    # | when(message.reactions | is_valid())\n",
    "    # | count(window=sliding(10, minutely())),\n",
    "\n",
    "    # TODO: the time of day\n",
    "    time: time_of(message), \n",
    "}\n",
    "\n",
    "let completion = message.user\n",
    "\n",
    "let examples = {\n",
    "    prompt: prompt, # TODO: Support lag: | lag(1),\n",
    "    completion: completion,\n",
    "}\n",
    "\n",
    "in examples | when($input.prompt | is_valid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training & validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(\n",
    "  examples.dataframe,\n",
    "  test_size=0.2, random_state=42\n",
    ")\n",
    "train.to_json(\"train.jsonl\", orient='records', lines=True)\n",
    "valid.to_json(\"valid.jsonl\", orient='records', lines=True)\n",
    "\n",
    "# Fine tune a model\n",
    "!openai api fine_tunes.create -t \"train.jsonl\" -v \"valid.jsonl\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
