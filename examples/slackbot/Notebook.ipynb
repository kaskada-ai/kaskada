{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235d821b-1ff8-4ef6-8f0b-559c95254479",
   "metadata": {},
   "source": [
    "# Slackbot Example\n",
    "\n",
    "SlackBot keeps you in the loop without disturbing your focus. Its personalized, intelligent AI continuously monitors your Slack workspace, alerting you to important conversations and freeing you to concentrate on what’s most important.\n",
    "\n",
    "SlackBot reads the full history of your (public) Slack workspace and trains a Generative AI model to predict when you need to engage with a conversation. This training process gives the AI a deep understanding of your interests, expertise, and relationships. Using this understanding, SlackBot watches conversations in real-time and notifies you when an important conversation is happening without you. With SlackBot200 you can focus on getting things done without worrying about missing out.\n",
    "\n",
    "In this notebook, you’ll see you how to build and deploy SlackBot in 15 minutes using only OpenAI’s API’s and open-source Python libraries - Data Science PhD not required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70440303",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai kaskada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4c44d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea2e95-6d9d-4068-ab98-8cf94bc4d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from slack_sdk.socket_mode import SocketModeClient\n",
    "import openai\n",
    "import sparrow_pi as k\n",
    "import sparrow_pi.sources as sources\n",
    "import openai\n",
    "import getpass\n",
    "import pyarrow\n",
    "\n",
    "# Initialize Kaskada with a local execution context.\n",
    "k.init_session()\n",
    "\n",
    "# Initialize OpenAI\n",
    "openai.api_key = getpass.getpass('OpenAI: API Key')\n",
    "\n",
    "# Initialize Slack\n",
    "slack = SocketModeClient(\n",
    "    app_token=getpass.getpass('Slack: App Token'),\n",
    "    web_client=getpass.getpass('Slack: Bot Token'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a144d-8d79-4943-b99b-d3470ee96283",
   "metadata": {},
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d4d50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_CONTEXT = \"\"\"\n",
    "You are a helpful assistant designed to suggest the Slack usernames of \n",
    "people who need to know about a Slack conversation.\n",
    "\n",
    "Only respond as a JSON list containing the Slack usernames of people to notify \n",
    "of the conversation, or return an empty list if no should be notified.\n",
    "\n",
    "The Slack conversation is as follows, formatted as a JSON object:\n",
    "\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ec0e3-c943-4974-922b-9b9c965ba0ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt(messages):\n",
    "    # A conversation starts when a new messages is more than 5 minutes after the previous message\n",
    "    #last_message = messages.lag(1)\n",
    "    #since_last_message = messages.time().seconds_since(last_message.time())\n",
    "    #conversation_start = since_last_message > k.minutes(5)\n",
    "\n",
    "    k.record({\n",
    "        # A list of all messages over the past 10 minutes (up to 100)\n",
    "        \"recent_messages\": messages\n",
    "            #.select(\"user\", \"type\", \"text\")\n",
    "            .select(False, \"user\", \"subtype\", \"text\")\n",
    "            #.collect(window=since(conversation_start), max=100),\n",
    "            .last(),\n",
    "\n",
    "        # How many messages have been reacted to in the conversation\n",
    "        \"reaction_count\": messages\n",
    "            #.filter(messages[\"reactions\"].is_not_null())\n",
    "            #.count(window=since(conversation_start)),\n",
    "            [\"reply_count\"].sum(),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2d959-d371-4026-9f8d-4ab26cfbf317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def examples(messages):\n",
    "    # We'll train ChatGPT to generate the user ID who will engage next\n",
    "    k.record({\n",
    "        # For each example, use the previous prompt\n",
    "        \"prompt\": prompt(messages)\n",
    "            #.lag(1),\n",
    "            .last(),\n",
    "\n",
    "        # ...and the current user ID\n",
    "        \"completion\": messages[\"user\"],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6bde5-9602-43e6-89bf-e0e1470fc7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data for OpenAI\n",
    "def format_prompt(prompt):\n",
    "    return SYSTEM_CONTEXT + json.dumps(prompt) + \"\\n\\n###\\n\\n\"\n",
    "def format_completion(completion):\n",
    "    return completion + \"###\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035f558-23bd-4b4d-95a0-ed5e8fece673",
   "metadata": {},
   "source": [
    "## Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d2a45-eb89-47ce-b471-a39ad8c7bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute examples from historical data\n",
    "#tl = examples(messages = k.source.read_parquet(\n",
    "#   entity_column=\"channel\", \n",
    "#    time_column=\"ts\", \n",
    "#    files=[\"./messages.parquet\"]))\n",
    "tl = examples(sources.ArrowSource(\"ts\", \"channel\", pandas.read_parquet(\"./messages.parquet\")))\n",
    "\n",
    "\n",
    "# Limit to the examples we want to use for training\n",
    "#tl = tl.filter(tl[\"prompt\"].is_not_null())\n",
    "#examples_df = tl.run().to_pandas()\n",
    "examples_df = tl.run()\n",
    "\n",
    "# Format for the OpenAI API\n",
    "examples_df[\"prompt\"] = examples_df[\"prompt\"].apply(format_prompt)\n",
    "examples_df[\"completion\"] = examples_df[\"completion\"].apply(format_completion)\n",
    "\n",
    "# Split training & validation\n",
    "train, valid = train_test_split(examples_df, test_size=0.2, random_state=42)\n",
    "train.to_json(\"train.jsonl\", orient='records', lines=True)\n",
    "valid.to_json(\"valid.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83914ada-d108-422b-b4c0-7a0d9576d031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "openai api fine_tunes.create -t \"train.jsonl\" -v \"valid.jsonl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e29109-cc00-4bf5-ba23-069e8db1f179",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Notify users of conversations they need to know about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540afff7-4ebc-427f-8205-1ed145e0c59a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Receive Slack messages in real-time\n",
    "live_messages = k.source.read_stream(entity_column=\"channel\", time_column=\"ts\")\n",
    "\n",
    "# Receive messages from Slack\n",
    "def handle_message(client, req):\n",
    "    # Acknowledge the message back to Slack\n",
    "    client.send_socket_mode_response(SocketModeResponse(envelope_id=req.envelope_id))\n",
    "    \n",
    "    # Deliver the message to Kaskada\n",
    "    live_messages.add_event(pyarrow.json.read_json(req.payload))\n",
    "client.socket_mode_request_listeners.append(handle_message)\n",
    "client.connect()\n",
    "\n",
    "# Handle messages in realtime\n",
    "for p in prompt(live_messages).run(starting=datetime.now()).to_generator():\n",
    "    \n",
    "    # Ask the model who should be notified\n",
    "    completions = openai.Completion.create(\n",
    "        model=\"ft-2zaA7qi0rxJduWQpdvOvmGn3\", \n",
    "        prompt=format_prompt(p),\n",
    "        max_tokens=10,\n",
    "        temperature=0,\n",
    "    )\n",
    "    users = json.loads(completions.choices[0].text)\n",
    "    \n",
    "    # Send notification to users\n",
    "    for user in users:\n",
    "        permalink = slack.web_client.chat_getPermalink(\n",
    "            channel=prompt[\"_entity\"],\n",
    "            message_ts=prompt[\"_time\"],\n",
    "        )[\"permalink\"]\n",
    "        \n",
    "        app_channel = slack.web_client.users_conversations(\n",
    "            types=\"im\",\n",
    "            user=user,\n",
    "        )[\"channels\"][0][\"id\"]\n",
    "        \n",
    "        slack.web_client.chat_postMessage(\n",
    "            channel=app_channel,\n",
    "            text=f'You put eyes on this message: <{link}|{message_text}>'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd2b13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Legacy Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d9d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext fenlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac261293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaskada.api.session import LocalBuilder\n",
    "from kaskada import table\n",
    "\n",
    "session = LocalBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7c0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#table.delete_table(\"Message\")\n",
    "\n",
    "table.create_table(\n",
    "  # The table's name\n",
    "  table_name = \"Message\",\n",
    "  # The name of the column in the data that contains the time associated with each row\n",
    "  time_column_name = \"ts\",\n",
    "  # The name of the column in the data that contains the entity key associated with each row\n",
    "  entity_key_column_name = \"channel\",\n",
    "  grouping_id = \"Channel\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8df2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "table.load(table_name = \"Message\", file = \"messages.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2b745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%fenl\n",
    "Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fenl\n",
    "let message = Message | when(Message.subtype == \"message\")\n",
    "\n",
    "let last_message = message.lag(1)\n",
    "let since_last_message = seconds_between(message.time_of(), last_message.time_of()) as i64\n",
    "let conversation_start = since_last_message > 5 * 60\n",
    "\n",
    "let prompt = {\n",
    "    # TODO: List rather than last\n",
    "    recent_messages: message | select_fields($input, \"user\", \"text\") | last(),\n",
    "\n",
    "    # # TODO: List support (for reactions field)\n",
    "    engage_count: message\n",
    "    | when(message.reactions | is_valid())\n",
    "    | count(window=since(conversation_start)),\n",
    "}\n",
    "\n",
    "let completion = message.user\n",
    "\n",
    "let examples = {\n",
    "    prompt: prompt, # TODO: Support lag: | lag(1),\n",
    "    completion: completion,\n",
    "}\n",
    "\n",
    "in examples | when($input.prompt | is_valid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training & validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(\n",
    "  examples.dataframe,\n",
    "  test_size=0.2, random_state=42\n",
    ")\n",
    "train.to_json(\"train.jsonl\", orient='records', lines=True)\n",
    "valid.to_json(\"valid.jsonl\", orient='records', lines=True)\n",
    "\n",
    "# Fine tune a model\n",
    "!openai api fine_tunes.create -t \"train.jsonl\" -v \"valid.jsonl\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
