{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "235d821b-1ff8-4ef6-8f0b-559c95254479",
   "metadata": {},
   "source": [
    "# Slackbot Example\n",
    "\n",
    "SlackBot keeps you in the loop without disturbing your focus. Its personalized, intelligent AI continuously monitors your Slack workspace, alerting you to important conversations and freeing you to concentrate on what’s most important.\n",
    "\n",
    "SlackBot reads the full history of your (public) Slack workspace and trains a Generative AI model to predict when you need to engage with a conversation. This training process gives the AI a deep understanding of your interests, expertise, and relationships. Using this understanding, SlackBot watches conversations in real-time and notifies you when an important conversation is happening without you. With SlackBot200 you can focus on getting things done without worrying about missing out.\n",
    "\n",
    "In this notebook, you’ll see you how to build and deploy SlackBot in 15 minutes using only OpenAI’s API’s and open-source Python libraries - Data Science PhD not required.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70440303",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai kaskada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ea2e95-6d9d-4068-ab98-8cf94bc4d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from slack_sdk.socket_mode import SocketModeClient, SocketModeResponse\n",
    "import sparrow_pi as kt\n",
    "import openai\n",
    "import getpass\n",
    "import pyarrow\n",
    "\n",
    "# Initialize Kaskada with a local execution context.\n",
    "kt.init_session()\n",
    "\n",
    "# Initialize OpenAI\n",
    "openai.api_key = getpass.getpass('OpenAI: API Key')\n",
    "\n",
    "# Initialize Slack\n",
    "slack = SocketModeClient(\n",
    "    app_token=getpass.getpass('Slack: App Token'),\n",
    "    web_client=getpass.getpass('Slack: Bot Token'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a144d-8d79-4943-b99b-d3470ee96283",
   "metadata": {},
   "source": [
    "## Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conversation(messages):\n",
    "    message_time = messages.col(\"ts\")\n",
    "    last_message_time = message_time.lag(1) # !!!\n",
    "    is_new_conversation = message_time.seconds_since(last_message_time) > 10 * 60\n",
    "\n",
    "    return messages \\\n",
    "        .select(\"user\", \"ts\", \"text\", \"reactions\") \\\n",
    "        .collect(window=kt.windows.Since(is_new_conversation), max=100) \\\n",
    "        .select(\"user\", \"ts\", \"text\") \\\n",
    "        .collect(window=kt.windows.Since(is_new_conversation), max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2d959-d371-4026-9f8d-4ab26cfbf317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_examples(messages):\n",
    "    duration = kt.minutes(5)  # !!!\n",
    "\n",
    "    coverstation = build_conversation(messages)\n",
    "    shifted_coversation = coverstation.shift_by(duration)  # !!!\n",
    "\n",
    "    reaction_users = coverstation.col(\"reactions\").col(\"name\").collect(kt.windows.Trailing(duration)).flatten()  # !!!\n",
    "    participating_users = coverstation.col(\"user\").collect(kt.windows.Trailing(duration))  # !!!\n",
    "    engaged_users = kt.union(reaction_users, participating_users)  # !!!\n",
    "\n",
    "    return kt.record({ \"prompt\": shifted_coversation, \"completion\": engaged_users}) \\\n",
    "        .filter(shifted_coversation.is_not_null())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0035f558-23bd-4b4d-95a0-ed5e8fece673",
   "metadata": {},
   "source": [
    "## Fine-tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d2a45-eb89-47ce-b471-a39ad8c7bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sparrow_pi.sources as sources\n",
    "\n",
    "messages = kt.sources.Parquet(\"./messages.parquet\", time = \"ts\", entity = \"channel\")\n",
    "messages = messages.with_key(kt.record({  # !!!\n",
    "        \"channel\": messages.col(\"channel\"),\n",
    "        \"thread\": messages.col(\"thread_ts\"),\n",
    "    }))\n",
    "examples = build_examples(messages)\n",
    "\n",
    "examples_df = examples.run().to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(examples_df.completion.explode())\n",
    "\n",
    "# Format for the OpenAI API\n",
    "def format_prompt(prompt):\n",
    "    return \"start -> \" + \"\\n\\n\".join([f' {msg.user} --> {msg.text} ' for msg in prompt]) + \"\\n\\n###\\n\\n\"\n",
    "examples_df.prompt = examples_df.prompt.apply(format_prompt)\n",
    "\n",
    "def format_completion(completion):\n",
    "    return \" \" + (\" \".join([le.transform(u) for u in completion]) if len(completion) > 0 else \"nil\") + \" end\"\n",
    "examples_df.completion = examples_df.completion.apply(format_completion)\n",
    "\n",
    "# Write examples to file\n",
    "examples_df.to_json(\"examples.jsonl\", orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83914ada-d108-422b-b4c0-7a0d9576d031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "from openai import cli\n",
    "\n",
    "# verifiy data format, split for training & validation\n",
    "args = SimpleNamespace(file='./examples.jsonl', quiet=True)\n",
    "cli.FineTune.prepare_data(args)\n",
    "training_id = cli.FineTune._get_or_upload('./examples_prepared_train.jsonl', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "resp = openai.FineTune.create(\n",
    "    training_file = training_id,\n",
    "    model = \"davinci\",\n",
    "    n_epochs = 2,\n",
    "    learning_rate_multiplier = 0.02,\n",
    "    suffix = \"coversation_users\"\n",
    ")\n",
    "print(f'Fine-tuning model with job ID: \"{resp[\"id\"]}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e29109-cc00-4bf5-ba23-069e8db1f179",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Notify users of conversations they need to know about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540afff7-4ebc-427f-8205-1ed145e0c59a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, math\n",
    "\n",
    "min_prob_for_response = 0.75\n",
    "\n",
    "# Receive Slack messages in real-time\n",
    "live_messages = kt.sources.read_stream(entity_column=\"channel\", time_column=\"ts\")\n",
    "\n",
    "# Receive messages from Slack\n",
    "def handle_message(client, req):\n",
    "    # Acknowledge the message back to Slack\n",
    "    client.send_socket_mode_response(SocketModeResponse(envelope_id=req.envelope_id))\n",
    "    \n",
    "    # Deliver the message to Kaskada\n",
    "    live_messages.add_event(pyarrow.json.read_json(req.payload))\n",
    "slack.socket_mode_request_listeners.append(handle_message)\n",
    "slack.connect()\n",
    "\n",
    "# Handle messages in realtime\n",
    "# A \"conversation\" is a list of messages\n",
    "for conversation in build_conversation(live_messages).start().to_generator():\n",
    "    if len(conversation) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Ask the model who should be notified\n",
    "    res = openai.Completion.create(\n",
    "        model=\"ft-2zaA7qi0rxJduWQpdvOvmGn3\", \n",
    "        prompt=format_prompt(conversation),\n",
    "        max_tokens=1,\n",
    "        temperature=0,\n",
    "        logprobs=5,\n",
    "    )\n",
    "\n",
    "    users = []\n",
    "    logprobs = res[\"choices\"][0][\"logprobs\"][\"top_logprobs\"][0]\n",
    "    for user in logprobs:\n",
    "        if math.exp(logprobs[user]) > min_prob_for_response:\n",
    "            # if `nil` user is an option, stop processing\n",
    "            if user == \"nil\":\n",
    "                users = []\n",
    "                break\n",
    "            users.append(user)\n",
    "\n",
    "    # alert on most recent message in conversation\n",
    "    msg = conversation.pop()\n",
    "    \n",
    "    # Send notification to users\n",
    "    for user in users:\n",
    "        user_id = le.inverse_transform(user)\n",
    "\n",
    "        link = slack.web_client.chat_getPermalink(\n",
    "            channel=msg[\"channel\"],\n",
    "            message_ts=msg[\"ts\"],\n",
    "        )[\"permalink\"]\n",
    "        \n",
    "        app_channel = slack.web_client.users_conversations(\n",
    "            types=\"im\",\n",
    "            user=user_id,\n",
    "        )[\"channels\"][0][\"id\"]\n",
    "        \n",
    "        slack.web_client.chat_postMessage(\n",
    "            channel=app_channel,\n",
    "            text=f'You may be interested in this converstation: <{link}|{msg[\"text\"]}>'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd2b13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Legacy Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d9d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext fenlmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac261293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaskada.api.session import LocalBuilder\n",
    "from kaskada import table\n",
    "\n",
    "session = LocalBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff7c0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#table.delete_table(\"Message\")\n",
    "\n",
    "table.create_table(\n",
    "  # The table's name\n",
    "  table_name = \"Message\",\n",
    "  # The name of the column in the data that contains the time associated with each row\n",
    "  time_column_name = \"ts\",\n",
    "  # The name of the column in the data that contains the entity key associated with each row\n",
    "  entity_key_column_name = \"channel\",\n",
    "  grouping_id = \"Channel\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8df2a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "table.load(table_name = \"Message\", file = \"messages.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2b745",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%fenl\n",
    "Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb3d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%fenl\n",
    "let message = Message | when(Message.subtype == \"message\")\n",
    "\n",
    "let last_message = message.lag(1)\n",
    "let since_last_message = seconds_between(message.time_of(), last_message.time_of()) as i64\n",
    "let conversation_start = since_last_message > 5 * 60\n",
    "\n",
    "let prompt = {\n",
    "    # TODO: List rather than last\n",
    "    recent_messages: message | select_fields($input, \"user\", \"text\") | last(),\n",
    "\n",
    "    # # TODO: List support (for reactions field)\n",
    "    engage_count: message\n",
    "    | when(message.reactions | is_valid())\n",
    "    | count(window=since(conversation_start)),\n",
    "}\n",
    "\n",
    "let completion = message.user\n",
    "\n",
    "let examples = {\n",
    "    prompt: prompt, # TODO: Support lag: | lag(1),\n",
    "    completion: completion,\n",
    "}\n",
    "\n",
    "in examples | when($input.prompt | is_valid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e895a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training & validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, valid = train_test_split(\n",
    "  examples.dataframe,\n",
    "  test_size=0.2, random_state=42\n",
    ")\n",
    "train.to_json(\"train.jsonl\", orient='records', lines=True)\n",
    "valid.to_json(\"valid.jsonl\", orient='records', lines=True)\n",
    "\n",
    "# Fine tune a model\n",
    "!openai api fine_tunes.create -t \"train.jsonl\" -v \"valid.jsonl\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
