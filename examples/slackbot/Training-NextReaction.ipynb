{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Reaction\n",
    "\n",
    "### For a set of recent messages, try to predict the reaction (if any) to the next message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, openai, random, time\n",
    "from openai import cli\n",
    "from types import SimpleNamespace\n",
    "\n",
    "work_dir = \"\"\n",
    "\n",
    "# Remember to remove your key from your code when you're done.\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Output Stage\n",
    "\n",
    "This is a Generative problem, so the goals for training aren't as strict.\n",
    "\n",
    "Goals:\n",
    "* prompt and completion length must not be longer than 2048 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New channel: articles\n",
      "New channel: conferences\n",
      "New channel: dev\n",
      "New channel: dev-ops\n",
      "New channel: fluff-posting\n",
      "New channel: games\n",
      "New channel: general\n",
      "New channel: inbound-leads\n",
      "New channel: on-call\n",
      "New channel: product\n",
      "New channel: random\n",
      "New channel: rust\n",
      "New channel: sales-team\n",
      "New channel: team-api\n",
      "New channel: team-compute\n"
     ]
    }
   ],
   "source": [
    "file1 = open(f'{work_dir}/messages.jsonl', 'r')\n",
    "file2 = open(f'{work_dir}/next_reaction.jsonl', 'w')\n",
    "\n",
    "current_channel = \"\"\n",
    "previous_training_example = \"\"\n",
    "recent_messages = []\n",
    "count = 0\n",
    "\n",
    "min_messages = 2\n",
    "max_messages = 5\n",
    "between_message_separator = \" \\n\\n\\n \"\n",
    "prompt_separator = \"\\n\\n###\\n\\n\"\n",
    "completion_separator = \" END\"\n",
    "reverse_messages = True\n",
    "\n",
    "while True:\n",
    "    line = file1.readline()\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "\n",
    "    data = json.loads(line)\n",
    "    text = data[\"text\"].strip()\n",
    "\n",
    "    # skip message if empty\n",
    "    if text == \"\":\n",
    "        continue\n",
    "\n",
    "    # skip message if it contains a code block\n",
    "    if text.find(\"```\") >= 0:\n",
    "        continue\n",
    "\n",
    "    channel = data[\"channel\"]\n",
    "    user_id = data[\"user\"]\n",
    "    reactions = data[\"reactions\"]\n",
    "\n",
    "    # restart message history count if the channel changes in the file\n",
    "    if channel != current_channel:\n",
    "        current_channel = channel\n",
    "        recent_messages = []\n",
    "        print(f'New channel: {current_channel}')\n",
    "\n",
    "    # add the recent message to the history.\n",
    "    # remove the oldest message if the size window is exceeded\n",
    "    recent_messages.append(text)\n",
    "    if len(recent_messages) > max_messages:\n",
    "        recent_messages.pop(0)\n",
    "\n",
    "    # if we are in the message history size window, prep to output an example\n",
    "    if len(recent_messages) > min_messages:\n",
    "        messages = recent_messages.copy()\n",
    "        if reverse_messages:\n",
    "            messages.reverse()\n",
    "        \n",
    "        prompt = between_message_separator.join(messages) \n",
    "        completion = json.dumps(reactions) if reactions else \"\"\n",
    "\n",
    "        training_example = { \"prompt\": f'{prompt}{prompt_separator}', \"completion\": f' {completion}{completion_separator}' }\n",
    "        training_example = json.dumps(training_example)\n",
    "\n",
    "        # if training example doesn't match the previous one, then output\n",
    "        if previous_training_example != training_example:\n",
    "            file2.write(training_example + \"\\n\")\n",
    "\n",
    "        previous_training_example = training_example\n",
    "\n",
    "file1.close()\n",
    "file2.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Verification Stage\n",
    "\n",
    "* make sure prompts end with same suffix\n",
    "* make sure tokens per example are less than 2048\n",
    "* ignore all other analysis\n",
    "  * we are training for *conditional generation*, but the data prep tool incorreclty assumes we are fine-tuning for *classifaction*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 19672 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- More than a third of your `completion` column/key is uppercase. Uppercase completions tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Lowercase all your data in column/key `completion` [Y/n]: Y\n",
      "- [Recommended] Would you like to split into training and validation set? [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified files to `/Users/eric.pinzur/Documents/slackbot2000/next_reaction_prepared_train.jsonl` and `/Users/eric.pinzur/Documents/slackbot2000/next_reaction_prepared_valid.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"/Users/eric.pinzur/Documents/slackbot2000/next_reaction_prepared_train.jsonl\" -v \"/Users/eric.pinzur/Documents/slackbot2000/next_reaction_prepared_valid.jsonl\" --compute_classification_metrics --classification_n_classes 507\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\" end\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 7.91 hours to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "args = SimpleNamespace(file=f'{work_dir}/next_reaction.jsonl', quiet=True)\n",
    "cli.FineTune.prepare_data(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Stage\n",
    "\n",
    "* First need to upload the training & validation files to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|██████████| 15.0M/15.0M [00:00<00:00, 30.6Git/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file from /Users/eric.pinzur/Documents/slackbot2000/next_reaction.jsonl: file-SZwB3ECG1qIRZfE3DOA6cTOr\n",
      "Status (training_file): uploaded \n",
      "Status (training_file): uploaded \n",
      "Status (training_file): uploaded \n",
      "Status (training_file): uploaded \n",
      "Status (training_file): uploaded \n",
      "Status (training_file): uploaded \n",
      "Status (training_file): uploaded \n",
      "Status (training_file): processed \n"
     ]
    }
   ],
   "source": [
    "training_file_name = f'{work_dir}/next_reaction.jsonl'\n",
    "\n",
    "def check_status(training_id):\n",
    "    train_status = openai.File.retrieve(training_id)[\"status\"]\n",
    "    print(f'Status (training_file): {train_status} ')\n",
    "    return (train_status)\n",
    "\n",
    "# Upload the training and validation dataset files to Azure OpenAI.\n",
    "training_id = cli.FineTune._get_or_upload(training_file_name, True)\n",
    "\n",
    "# Check on the upload status of the training dataset file.\n",
    "(train_status) = check_status(training_id)\n",
    "\n",
    "# Poll and display the upload status once a second until both files have either\n",
    "# succeeded or failed to upload.\n",
    "while train_status not in [\"succeeded\", \"failed\", \"processed\"]:\n",
    "    time.sleep(1)\n",
    "    (train_status) = check_status(training_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_id=\"file-SZwB3ECG1qIRZfE3DOA6cTOr\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start a fine-tuning Job\n",
    "\n",
    "* no validation file since this is not a classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning model with job ID: ft-Uy0jb2sUxNxE347gtk2Ixd5p\n"
     ]
    }
   ],
   "source": [
    "# This example defines a fine-tune job that creates a customized model based on curie, \n",
    "# with just a single pass through the training data. The job also provides classification-\n",
    "# specific metrics, using our validation data, at the end of that epoch.\n",
    "create_args = {\n",
    "    \"training_file\": training_id,\n",
    "    \"model\": \"ada\",\n",
    "    \"n_epochs\": 1,\n",
    "    \"suffix\": \"next_reaction_full_kaskada\"\n",
    "}\n",
    "# Create the fine-tune job and retrieve the job ID\n",
    "# and status from the response.\n",
    "resp = openai.FineTune.create(**create_args)\n",
    "job_id = resp[\"id\"]\n",
    "status = resp[\"status\"]\n",
    "\n",
    "# You can use the job ID to monitor the status of the fine-tune job.\n",
    "# The fine-tune job may take some time to start and complete.\n",
    "print(f'Fine-tuning model with job ID: {job_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = \"ft-Uy0jb2sUxNxE347gtk2Ixd5p\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait for the fine-tuning to start\n",
    "\n",
    "* Note that it can take several hours for the job to move from the `pending` state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the status of our fine-tune job.\n",
    "status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "\n",
    "# If the job isn't yet done, poll it every 2 seconds.\n",
    "if status not in [\"succeeded\", \"failed\"]:\n",
    "    print(f'Job not in terminal status: {status}. Waiting.')\n",
    "    while status not in [\"succeeded\", \"failed\"]:\n",
    "        time.sleep(5)\n",
    "        status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
    "        print(f'Status: {status}')\n",
    "else:\n",
    "    print(f'Fine-tune job {job_id} finished with status: {status}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check fine-tuning events\n",
    "\n",
    "* Lets us know specifics about the fine-tuning job\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the events of our fine-tune job.\n",
    "events = openai.FineTune.stream_events(id=job_id)\n",
    "\n",
    "for event in events:\n",
    "    print(event)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Training Results\n",
    "\n",
    "* download the results file(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputted results to: /Users/eric.pinzur/Documents/slackbot2000/next_reaction_results_0.csv\n"
     ]
    }
   ],
   "source": [
    "file_prefix = \"next_reaction_results\"\n",
    "\n",
    "result = openai.FineTune.retrieve(id=job_id)\n",
    "count = 0\n",
    "for result_file in result[\"result_files\"]:\n",
    "    file_name = f'{work_dir}/{file_prefix}_{count}.csv'\n",
    "    file = open(file_name, 'wb')\n",
    "    file.write(openai.File.download(id=result_file[\"id\"]))\n",
    "    file.close()\n",
    "    print(f'Outputted results to: {file_name}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
