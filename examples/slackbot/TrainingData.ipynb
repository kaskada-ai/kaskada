{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Prep\n",
    "\n",
    "```sql\n",
    "copy(\n",
    "    select\n",
    "      -- type,\n",
    "      -- subtype           ,\n",
    "      ts,\n",
    "      to_timestamp(cast(ts as bigint)) as ts_timedate,\n",
    "      user              ,\n",
    "      text              ,\n",
    "      -- client_msg_id     ,\n",
    "      -- blocks            ,\n",
    "      -- team              ,\n",
    "      -- user_team         ,\n",
    "      -- source_team       ,\n",
    "      -- user_profile      ,\n",
    "      -- inviter           ,\n",
    "      -- edited            ,\n",
    "      reactions         ,\n",
    "      thread_ts,\n",
    "      to_timestamp(cast(thread_ts as bigint)) as thread_ts_timedate,\n",
    "      -- reply_count       ,\n",
    "      -- reply_users_count ,\n",
    "      -- latest_reply      ,\n",
    "      -- reply_users       ,\n",
    "      replies           ,\n",
    "      -- is_locked         ,\n",
    "      -- subscribed        ,\n",
    "      -- last_read         ,\n",
    "      parent_user_id    ,\n",
    "      regexp_extract(filename, 'kaskada-slack-export/(.+)/\\d{4}-\\d{2}-\\d{2}.json', 1) as channel\n",
    "    from (\n",
    "        select * from read_json_auto('kaskada-slack-export/*/*.json',\n",
    "            format='array',\n",
    "            filename=true,\n",
    "            union_by_name=true)\n",
    "    )\n",
    "    where subtype is null\n",
    ") to 'messages.jsonl' (FORMAT JSON)\n",
    ";\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New channel: team-api\n",
      "{'prompt': 'Did some quick digging into release options for go binaries, and this looks like a pretty nice tool: \\n\\n\\n Let me know if you need anything else for it \\n\\n\\n <@U016TM9NXEY> I’m making various changes to your wren MR 3568', 'completion': ' ULJD5H2A2'}\n",
      "{'prompt': '<https://goreleaser.com/customization/blob/> \\n\\n\\n Did some quick digging into release options for go binaries, and this looks like a pretty nice tool: \\n\\n\\n Let me know if you need anything else for it \\n\\n\\n <@U016TM9NXEY> I’m making various changes to your wren MR 3568', 'completion': ' ULJD5H2A2'}\n",
      "{'prompt': 'Has a bunch of options for publishing - one is to push to S3. So we could create a public bucket and publish into it pretty easily \\n\\n\\n <https://goreleaser.com/customization/blob/> \\n\\n\\n Did some quick digging into release options for go binaries, and this looks like a pretty nice tool: \\n\\n\\n Let me know if you need anything else for it \\n\\n\\n <@U016TM9NXEY> I’m making various changes to your wren MR 3568', 'completion': ' U017T5TFW58'}\n",
      "{'prompt': '<@UU5C7MNMA> got a sec to help us look at integration test funkiness? <https://kaskada.zoom.us/j/87046422556> \\n\\n\\n Has a bunch of options for publishing - one is to push to S3. So we could create a public bucket and publish into it pretty easily \\n\\n\\n <https://goreleaser.com/customization/blob/> \\n\\n\\n Did some quick digging into release options for go binaries, and this looks like a pretty nice tool: \\n\\n\\n Let me know if you need anything else for it', 'completion': ' UCZ4VJF6J'}\n",
      "{'prompt': \"<@U017T5TFW58> <@U012CLUV1KJ> <https://onsi.github.io/ginkgo/#spec-randomization>\\n\\n&gt; Ginkgo's default behavior is to only randomize the order of top-level containers -- the specs within those containers continue to run in the order in which they are specified in the test files. This is helpful when developing specs as it mitigates the cognitive overload of having specs within a container continuously change the order in which they run during a debugging session. \\n\\n\\n <@UU5C7MNMA> got a sec to help us look at integration test funkiness? <https://kaskada.zoom.us/j/87046422556> \\n\\n\\n Has a bunch of options for publishing - one is to push to S3. So we could create a public bucket and publish into it pretty easily \\n\\n\\n <https://goreleaser.com/customization/blob/> \\n\\n\\n Did some quick digging into release options for go binaries, and this looks like a pretty nice tool:\", 'completion': ' UCZ4VJF6J'}\n",
      "{'prompt': \"As Jordan pointed out above, this wasn't limited to the panic tests. The root cause was that the incemental tests weren't deleting the table they created (`purchases`), so they would lead to a later test failing if it tried to create `purchases`. Since the test file ordering is random, it led to flakiness (with a high failure rate, since there are ~6 files that create it that could be chosen, and if any of them came after the incremental test we would see failure). \\n\\n\\n <@U017T5TFW58> <@U012CLUV1KJ> <https://onsi.github.io/ginkgo/#spec-randomization>\\n\\n&gt; Ginkgo's default behavior is to only randomize the order of top-level containers -- the specs within those containers continue to run in the order in which they are specified in the test files. This is helpful when developing specs as it mitigates the cognitive overload of having specs within a container continuously change the order in which they run during a debugging session. \\n\\n\\n <@UU5C7MNMA> got a sec to help us look at integration test funkiness? <https://kaskada.zoom.us/j/87046422556> \\n\\n\\n Has a bunch of options for publishing - one is to push to S3. So we could create a public bucket and publish into it pretty easily \\n\\n\\n <https://goreleaser.com/customization/blob/>\", 'completion': ' U017T5TFW58'}\n",
      "{'prompt': \"Where `containers` are basically `Describe`, `Context` or `When`. Neat. <https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes> \\n\\n\\n As Jordan pointed out above, this wasn't limited to the panic tests. The root cause was that the incemental tests weren't deleting the table they created (`purchases`), so they would lead to a later test failing if it tried to create `purchases`. Since the test file ordering is random, it led to flakiness (with a high failure rate, since there are ~6 files that create it that could be chosen, and if any of them came after the incremental test we would see failure). \\n\\n\\n <@U017T5TFW58> <@U012CLUV1KJ> <https://onsi.github.io/ginkgo/#spec-randomization>\\n\\n&gt; Ginkgo's default behavior is to only randomize the order of top-level containers -- the specs within those containers continue to run in the order in which they are specified in the test files. This is helpful when developing specs as it mitigates the cognitive overload of having specs within a container continuously change the order in which they run during a debugging session. \\n\\n\\n <@UU5C7MNMA> got a sec to help us look at integration test funkiness? <https://kaskada.zoom.us/j/87046422556> \\n\\n\\n Has a bunch of options for publishing - one is to push to S3. So we could create a public bucket and publish into it pretty easily\", 'completion': ' UCZ4VJF6J'}\n",
      "{'prompt': 'Question: Is there a reason we don\\'t just publish the `Dockerfile.generate` to ECR and pull it down on local machines for `make proto/generate`? (seeing \"takes about 45 minutes to run\" makes me think it would be good to share) \\n\\n\\n Where `containers` are basically `Describe`, `Context` or `When`. Neat. <https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes> \\n\\n\\n As Jordan pointed out above, this wasn\\'t limited to the panic tests. The root cause was that the incemental tests weren\\'t deleting the table they created (`purchases`), so they would lead to a later test failing if it tried to create `purchases`. Since the test file ordering is random, it led to flakiness (with a high failure rate, since there are ~6 files that create it that could be chosen, and if any of them came after the incremental test we would see failure). \\n\\n\\n <@U017T5TFW58> <@U012CLUV1KJ> <https://onsi.github.io/ginkgo/#spec-randomization>\\n\\n&gt; Ginkgo\\'s default behavior is to only randomize the order of top-level containers -- the specs within those containers continue to run in the order in which they are specified in the test files. This is helpful when developing specs as it mitigates the cognitive overload of having specs within a container continuously change the order in which they run during a debugging session. \\n\\n\\n <@UU5C7MNMA> got a sec to help us look at integration test funkiness? <https://kaskada.zoom.us/j/87046422556>', 'completion': ' UCZ4VJF6J'}\n",
      "{'prompt': 'I believe that <https://gitlab.com/kaskada/kaskada/-/merge_requests/3576> is ready for another :eyes:. I\\'ve made the Sparrow changes for the new API, looking to generate Go protos and update Wren (although having to build the generate image, so that\\'ll likely take a while). \\n\\n\\n Question: Is there a reason we don\\'t just publish the `Dockerfile.generate` to ECR and pull it down on local machines for `make proto/generate`? (seeing \"takes about 45 minutes to run\" makes me think it would be good to share) \\n\\n\\n Where `containers` are basically `Describe`, `Context` or `When`. Neat. <https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes> \\n\\n\\n As Jordan pointed out above, this wasn\\'t limited to the panic tests. The root cause was that the incemental tests weren\\'t deleting the table they created (`purchases`), so they would lead to a later test failing if it tried to create `purchases`. Since the test file ordering is random, it led to flakiness (with a high failure rate, since there are ~6 files that create it that could be chosen, and if any of them came after the incremental test we would see failure). \\n\\n\\n <@U017T5TFW58> <@U012CLUV1KJ> <https://onsi.github.io/ginkgo/#spec-randomization>\\n\\n&gt; Ginkgo\\'s default behavior is to only randomize the order of top-level containers -- the specs within those containers continue to run in the order in which they are specified in the test files. This is helpful when developing specs as it mitigates the cognitive overload of having specs within a container continuously change the order in which they run during a debugging session.', 'completion': ' UU5C7MNMA'}\n",
      "{'prompt': 'good idea \\n\\n\\n I believe that <https://gitlab.com/kaskada/kaskada/-/merge_requests/3576> is ready for another :eyes:. I\\'ve made the Sparrow changes for the new API, looking to generate Go protos and update Wren (although having to build the generate image, so that\\'ll likely take a while). \\n\\n\\n Question: Is there a reason we don\\'t just publish the `Dockerfile.generate` to ECR and pull it down on local machines for `make proto/generate`? (seeing \"takes about 45 minutes to run\" makes me think it would be good to share) \\n\\n\\n Where `containers` are basically `Describe`, `Context` or `When`. Neat. <https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes> \\n\\n\\n As Jordan pointed out above, this wasn\\'t limited to the panic tests. The root cause was that the incemental tests weren\\'t deleting the table they created (`purchases`), so they would lead to a later test failing if it tried to create `purchases`. Since the test file ordering is random, it led to flakiness (with a high failure rate, since there are ~6 files that create it that could be chosen, and if any of them came after the incremental test we would see failure).', 'completion': ' UU5C7MNMA'}\n",
      "{'prompt': '<@U016TM9NXEY> are you avail to review your MR together now? \\n\\n\\n good idea \\n\\n\\n I believe that <https://gitlab.com/kaskada/kaskada/-/merge_requests/3576> is ready for another :eyes:. I\\'ve made the Sparrow changes for the new API, looking to generate Go protos and update Wren (although having to build the generate image, so that\\'ll likely take a while). \\n\\n\\n Question: Is there a reason we don\\'t just publish the `Dockerfile.generate` to ECR and pull it down on local machines for `make proto/generate`? (seeing \"takes about 45 minutes to run\" makes me think it would be good to share) \\n\\n\\n Where `containers` are basically `Describe`, `Context` or `When`. Neat. <https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes>', 'completion': ' U016TM9NXEY'}\n"
     ]
    }
   ],
   "source": [
    "## prompt is last 5-ish messages, completion is next user to write.\n",
    "\n",
    "import json\n",
    "\n",
    "file1 = open('/Users/eric.pinzur/Documents/messages.jsonl', 'r')\n",
    "\n",
    "current_channel = \"\"\n",
    "recent_messages = []\n",
    "min_messages = 2\n",
    "max_messages = 5\n",
    "count = 0\n",
    "while True:\n",
    "    line = file1.readline()\n",
    "\n",
    "    if not line:\n",
    "        break\n",
    "\n",
    "    data = json.loads(line)\n",
    "    channel = data[\"channel\"]\n",
    "    text = data[\"text\"]\n",
    "    user = data[\"user\"]\n",
    "    replies = data[\"replies\"]\n",
    "    reactions = data[\"reactions\"]\n",
    "    between_message_separator = \" \\n\\n\\n \"\n",
    "    reverse_messages = True\n",
    "\n",
    "    if channel != current_channel:\n",
    "        current_channel = channel\n",
    "        recent_messages = []\n",
    "        print(f'New channel: {current_channel}')\n",
    "\n",
    "    if len(recent_messages) > min_messages:\n",
    "        messages = recent_messages.copy()\n",
    "        if reverse_messages:\n",
    "            messages.reverse()\n",
    "        prompt = between_message_separator.join(messages)\n",
    "        training_example = { \"prompt\": prompt, \"completion\": \" \" + user}\n",
    "        print(training_example)\n",
    "        count += 1\n",
    "        if count > 10:\n",
    "            break\n",
    "\n",
    "    recent_messages.append(text)\n",
    "    if len(recent_messages) > max_messages:\n",
    "        recent_messages.pop(0)\n",
    "\n",
    "file1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
